{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Machine Learning Foundation\n\n## Section 1, Part e: Hypothesis Testing \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives: \n\nAfter this discussion, you should be able to: \n* Know the difference between a null and alternative hypothesis\n* Write your own set of hypotheses for testing\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install(['matplotlib', 'numpy', 'scipy'])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# see https://ipython.readthedocs.io/en/stable/interactive/magics.html\n%pylab inline\n\n%config InlineBackend.figure_formats = ['svg']\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats \nimport math",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Null Hypothesis\n\nI claim that I can use mystical abilities to predict the outcome of coin flips.\n\nYou don't think I can.\n\nHow can we test it?\n\nWe do an experiment in which I call 100 coin flips. I get 57 right.\n\nAm I special or not?\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "--- \n\n### Determining the Null and Alternative Hypothesis\n\nWrite the null and alternative hypotheses!\n\nNull: \n\nAlternative:\n\n---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Null:** I'm not special; my true rate of flip prediction is 0.5. \n\nBut even under this hypothesis, I could get 57 out of 100 right. So did I get lucky (by random chance) or am I mystical?\n\n**Alternative:** My true rate of flip prediction is greater than 0.5.\n\nThe thing we're measuring from the experiment, or **test statistic**, is the number of correct flip predictions out of 100.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n\nIf the null hypothesis is correct, the test statistic is binomial distributed with parameters `n = 100` and `p = 0.5`. That is, if we repeated the whole experiment many times, we would see such a distribution for all the results.\n\nSo if the null hypothesis is correct, how likely is it that I got 57 or more coin flips correct?\n\nBefore we check (really, before we do the experiment) we decide what would convince us that I have ESP. The choice of a cutoff at 5% probability is common. That is, if we would only see data as extreme as we've seen less than 5% of the time, we'll say that seems too unlikely and we will conclude that we don't think the null hypothesis is true.\n\n---\n\nWe have two outcomes, one with probability (p) and the other with probability (1-p) of happening (remember the axioms of probability?), so we know the [binomial](https://en.wikipedia.org/wiki/Binomial_distribution?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork837-2023-01-01) [distribution](http://mathworld.wolfram.com/BinomialDistribution.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork837-2023-01-01) is the [right tool for this analysis](https://homepage.divms.uiowa.edu/~mbognar/applets/bin.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork837-2023-01-01).\n\nIn the case of the binomial distribution, which is discrete and not too complicated mathematically, we could just work out the probability. But in general we'll rely on some existing functionality. (In a traditional statistics class, this is the part where we'd turn to a table in the back of the book.)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from scipy.stats import binom\nprob = 1 - binom.cdf(56, 100, 0.5)\n\nprint(str(round(prob*100, 1))+\"%\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The probability of getting 57 or more correct is about 9.7%. This is more than 5%, so we can't reject the null and conclude that I (probably) don't have mystical powers.\n\n---\n\nConversely, we can figure out what the 95% cutoff is beforehand.\n\n--- \n\n### Exercise\n\nFind the number of coin flips a person would need to guess correctly for us to believe they're clairvoyant.\n\n---\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from scipy.stats import binom\nprint(binom.ppf(0.95,100,0.5)+1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Which means, one should get 59 tosses or more to be considered clairvoyant. And we will say the person has predictive power with a confidence level of 95%.\n\n---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## A More Specific Claim\n\nSo far so good. What if instead I said, \"I'm not perfect, but I can predict coin tosses 60% of the time. Which is still good, which is still valuable.\"\n\nWhat do we do in this case? Sure, we can do exactly what we did earlier and when I predict 57 times, we can reject my claim.\n\nBut what if I say, \"Wait a minute. I said 60 and I got 57, that sounds pretty good to me.\"\n\nInterpretation:\n> \"I happened to have a poor guessing day, and that's why my results aren't quite statistically significant!\"\n\nWhat do we say to that? The issue here is that there is no longer a single null hypothesis that we prove or disprove. Instead, **we have two competing hypotheses**:\n    * Hypothesis A: There is no predictive power\n    * Hypothesis B: There is a 60% predictive power\n\nEach is a normal curve, with one centered at 50% and the other at 60%.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mu = 50\nvariance = 10\nsigma = math.sqrt(variance)\nx = np.linspace(1, 100, 200)\nplt.plot(x,stats.norm.pdf(x, mu, sigma))\n\nmu = 60\nvariance = 10\nsigma = math.sqrt(variance)\nx = np.linspace(1, 100, 200)\nplt.plot(x,stats.norm.pdf(x, mu, sigma))\n\nplt.xlim(30,80)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**And 57 correct guesses falls within the 95% confidence of both the curves:**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print (1 - binom.cdf(57, 100, 0.5))\nprint (binom.cdf(57, 100, 0.6))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "What now? There just isn't enough data to achieve a confidence of 95%. There are few things we can do.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 1) Decrease confidence\n\n\nSince we have a claim at 50 and 60, we can pick the mid-point, which is 55. We can say if I can predict over 55, then I have predictive power. This would mean that we have decreased our confidence level.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print (1 - binom.cdf(55, 100, 0.5))\nprint (binom.cdf(54, 100, 0.6))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "** At an 87% percent confidence level, we can say that I have some predictive power, since I got 57 tosses correct.**\n\nNot ideal; we picked a number, which is prone to bias, rather than a confidence interval.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 2) Be biased\n\nBut it is not neccessary that we bias the two hypotheses equally and pick the midpoint the way we did. The cut-off point can be anywhere. Currently, our error margins are even. The chance that someone has predictive power and we say no is 13% and the chance that someone has no power and we say they do is also 13%. As we change the cutoff, one error goes down and the other goes way up.\n\nFor example, if we stuck with the original 95% on a coin being fair:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "binom.ppf(0.95, 100, 0.5) #this is the inverse of the cdf functions above",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Then our cutff is 58. Our two errors will be:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print (1-binom.cdf(58, 100, 0.5))\nprint (binom.cdf(58, 100, 0.6))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "5% chance someone has no power and we say they do. But a 38% chance someone has predictive power and we say no. Which depending on the problem might be exactly what we want. These two types of errors are called Type I and Type II. And we have the choice of biasing against one or the other. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 3) Increase sample size\n\nThe best scenario though is to increase the sample size. Imagine what happens we did 1000 tosses instead of 100.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mu = 50\nvariance = 1\nsigma = math.sqrt(variance)\nx = np.linspace(1, 100, 1000)\nplt.plot(x,stats.norm.pdf(x, mu, sigma))\n\nmu = 60\nvariance = 1\nsigma = math.sqrt(variance)\nx = np.linspace(1, 100, 1000)\nplt.plot(x,stats.norm.pdf(x, mu, sigma))\n\nplt.xlim(45,65)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The two normal curves are completely seperated now.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print (binom.ppf(0.95,1000,0.5))\nprint (binom.ppf(0.05,1000,0.6))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n### Exercise\n\nWhat are our errors now?\n\n---\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print (1-binom.cdf(550, 1000, 0.5))\nprint (binom.cdf(550, 1000, 0.6))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**With a cutoff of 550, both our errors come down to under 0.1%.**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n### Machine Learning Foundation (C) 2020 IBM Corporation\n",
      "metadata": {}
    }
  ]
}